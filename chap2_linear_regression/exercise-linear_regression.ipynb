{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 说明\n",
    "\n",
    "请按照填空顺序编号分别完成 参数优化，不同基函数的实现"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def load_data(filename):\n",
    "    \"\"\"载入数据。\"\"\"\n",
    "    xys = []\n",
    "    with open(filename, 'r') as f:\n",
    "        for line in f:\n",
    "            xys.append(map(float, line.strip().split()))\n",
    "        xs, ys = zip(*xys)\n",
    "        return np.asarray(xs), np.asarray(ys)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "centers:[ 0.          2.77777778  5.55555556  8.33333333 11.11111111 13.88888889\n 16.66666667 19.44444444 22.22222222 25.        ]\nwidth:2.7777777777777777\nx expand:[[ 2]\n [ 3]\n [ 4]\n [ 5]\n [ 6]\n [ 7]\n [ 8]\n [ 9]\n [10]\n [11]]\nx concatenate:[[ 2  2  2  2  2  2  2  2  2  2]\n [ 3  3  3  3  3  3  3  3  3  3]\n [ 4  4  4  4  4  4  4  4  4  4]\n [ 5  5  5  5  5  5  5  5  5  5]\n [ 6  6  6  6  6  6  6  6  6  6]\n [ 7  7  7  7  7  7  7  7  7  7]\n [ 8  8  8  8  8  8  8  8  8  8]\n [ 9  9  9  9  9  9  9  9  9  9]\n [10 10 10 10 10 10 10 10 10 10]\n [11 11 11 11 11 11 11 11 11 11]]\nout:[[ 0.72 -0.28 -1.28 -2.28 -3.28 -4.28 -5.28 -6.28 -7.28 -8.28]\n [ 1.08  0.08 -0.92 -1.92 -2.92 -3.92 -4.92 -5.92 -6.92 -7.92]\n [ 1.44  0.44 -0.56 -1.56 -2.56 -3.56 -4.56 -5.56 -6.56 -7.56]\n [ 1.8   0.8  -0.2  -1.2  -2.2  -3.2  -4.2  -5.2  -6.2  -7.2 ]\n [ 2.16  1.16  0.16 -0.84 -1.84 -2.84 -3.84 -4.84 -5.84 -6.84]\n [ 2.52  1.52  0.52 -0.48 -1.48 -2.48 -3.48 -4.48 -5.48 -6.48]\n [ 2.88  1.88  0.88 -0.12 -1.12 -2.12 -3.12 -4.12 -5.12 -6.12]\n [ 3.24  2.24  1.24  0.24 -0.76 -1.76 -2.76 -3.76 -4.76 -5.76]\n [ 3.6   2.6   1.6   0.6  -0.4  -1.4  -2.4  -3.4  -4.4  -5.4 ]\n [ 3.96  2.96  1.96  0.96 -0.04 -1.04 -2.04 -3.04 -4.04 -5.04]]\n"
    }
   ],
   "source": [
    "# 测试一些函数\n",
    "feature_num = 10\n",
    "x = [2,3,4,5,6,7,8,9,10,11]\n",
    "centers = np.linspace(0,25,10)\n",
    "print('centers:'+str(centers))\n",
    "width = 1.0 * (centers[1] - centers[0])\n",
    "print('width:'+str(width))\n",
    "x = np.expand_dims(x,axis=1)\n",
    "print('x expand:'+str(x))\n",
    "x = np.concatenate([x]*feature_num, axis=1)\n",
    "print('x concatenate:'+str(x))\n",
    "out = (x-centers)/width\n",
    "print('out:'+str(out)) \n",
    "ret = np.exp(-0.5 * out ** 2)\n",
    "print('ret:'+str(ret))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 不同的基函数 (basis function)的实现 填空顺序 2\n",
    "\n",
    "请分别在这里实现“多项式基函数”以及“高斯基函数”\n",
    "\n",
    "其中以及训练集的x的范围在0-25之间"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def identity_basis(x):\n",
    "    ret = np.expand_dims(x, axis=1)\n",
    "    return ret\n",
    "\n",
    "\n",
    "def multinomial_basis(x, feature_num=10):\n",
    "    '''多项式基函数'''\n",
    "    x = np.expand_dims(x, axis=1) # shape(N, 1)\n",
    "    #==========\n",
    "    #todo '''请实现多项式基函数'''\n",
    "    #==========\n",
    "    ret = np.power(x,np.insert(np.arange(1,x.shape[0]+1),0,1))\n",
    "    return ret\n",
    "\n",
    "\n",
    "def gaussian_basis(x, feature_num=10):\n",
    "    '''高斯基函数'''\n",
    "    #==========\n",
    "    #todo '''请实现高斯基函数'''\n",
    "    #==========\n",
    "    ret = None\n",
    "    return ret\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 返回一个训练好的模型 填空顺序 1 用最小二乘法进行模型优化 \n",
    "## 填空顺序 3 用梯度下降进行模型优化\n",
    "> 先完成最小二乘法的优化 (参考书中第二章 2.3中的公式)\n",
    "\n",
    "> 再完成梯度下降的优化   (参考书中第二章 2.3中的公式)\n",
    "\n",
    "在main中利用训练集训练好模型的参数，并且返回一个训练好的模型。\n",
    "\n",
    "计算出一个优化后的w，请分别使用最小二乘法以及梯度下降两种办法优化w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(x_train, y_train):\n",
    "    \"\"\"\n",
    "    训练模型，并返回从x到y的映射。\n",
    "    \n",
    "    \"\"\"\n",
    "    basis_func = identity_basis\n",
    "    phi0 = np.expand_dims(np.ones_like(x_train), axis=1)\n",
    "    phi1 = basis_func(x_train)\n",
    "    phi = np.concatenate([phi0, phi1], axis=1)\n",
    "    \n",
    "    \n",
    "    #==========\n",
    "    #todo '''计算出一个优化后的w，请分别使用最小二乘法以及梯度下降两种办法优化w'''\n",
    "    #==========\n",
    "    \n",
    "    def f(x):\n",
    "        phi0 = np.expand_dims(np.ones_like(x), axis=1)\n",
    "        phi1 = basis_func(x)\n",
    "        phi = np.concatenate([phi0, phi1], axis=1)\n",
    "        y = np.dot(phi, w)\n",
    "        return y\n",
    "\n",
    "    return f"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 评估结果 \n",
    "> 没有需要填写的代码，但是建议读懂"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(ys, ys_pred):\n",
    "    \"\"\"评估模型。\"\"\"\n",
    "    std = np.sqrt(np.mean(np.abs(ys - ys_pred) ** 2))\n",
    "    return std\n",
    "\n",
    "# 程序主入口（建议不要改动以下函数的接口）\n",
    "if __name__ == '__main__':\n",
    "    train_file = 'train.txt'\n",
    "    test_file = 'test.txt'\n",
    "    # 载入数据\n",
    "    x_train, y_train = load_data(train_file)\n",
    "    x_test, y_test = load_data(test_file)\n",
    "    print(x_train.shape)\n",
    "    print(x_test.shape)\n",
    "\n",
    "    # 使用线性回归训练模型，返回一个函数f()使得y = f(x)\n",
    "    f = main(x_train, y_train)\n",
    "\n",
    "    y_train_pred = f(x_train)\n",
    "    std = evaluate(y_train, y_train_pred)\n",
    "    print('训练集预测值与真实值的标准差：{:.1f}'.format(std))\n",
    "    \n",
    "    # 计算预测的输出值\n",
    "    y_test_pred = f(x_test)\n",
    "    # 使用测试集评估模型\n",
    "    std = evaluate(y_test, y_test_pred)\n",
    "    print('预测值与真实值的标准差：{:.1f}'.format(std))\n",
    "\n",
    "    #显示结果\n",
    "    plt.plot(x_train, y_train, 'ro', markersize=3)\n",
    "#     plt.plot(x_test, y_test, 'k')\n",
    "    plt.plot(x_test, y_test_pred, 'k')\n",
    "    plt.xlabel('x')\n",
    "    plt.ylabel('y')\n",
    "    plt.title('Linear Regression')\n",
    "    plt.legend(['train', 'test', 'pred'])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "Python 3.8.3 64-bit ('base': conda)",
   "display_name": "Python 3.8.3 64-bit ('base': conda)",
   "metadata": {
    "interpreter": {
     "hash": "8ab0d968002a578cf1e1aa041721a175249ba338f6da29efa5ef1a380c630376"
    }
   }
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3-final"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "source": [],
    "metadata": {
     "collapsed": false
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}